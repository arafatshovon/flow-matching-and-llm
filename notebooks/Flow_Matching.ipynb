{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1fb875d2",
      "metadata": {},
      "source": [
        "## Flow Matching - Dummy Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63fba54d",
      "metadata": {
        "id": "63fba54d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits, make_moons\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967debb3",
      "metadata": {
        "id": "967debb3"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d44c626b",
      "metadata": {
        "id": "d44c626b"
      },
      "source": [
        "## Flow Matcing Example Using Checker Board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "952507d3",
      "metadata": {
        "id": "952507d3"
      },
      "outputs": [],
      "source": [
        "def make_checker_board(num_sample:int) -> torch.tensor:\n",
        "    \"\"\"\n",
        "    Returns a Checker Board Pattern of dim (num_sample*16, 2)\n",
        "    \"\"\"\n",
        "    dim = 2\n",
        "    noise1 = torch.FloatTensor(num_sample, dim).uniform_(0.0, 1.0)\n",
        "    noise2 = torch.FloatTensor(num_sample, dim).uniform_(1.0, 2.0)\n",
        "    noise3 = torch.FloatTensor(num_sample, dim).uniform_(2.0, 3.0) - torch.tensor([0.0, 2.0])\n",
        "    noise4 = torch.FloatTensor(num_sample, dim).uniform_(3.0, 4.0) - torch.tensor([0.0, 2.0])\n",
        "\n",
        "    first_quad = torch.cat((noise1, noise2), dim=0)\n",
        "    second_quad = first_quad - torch.tensor([2.0, 0.0])\n",
        "    third_quad = first_quad * torch.tensor([-1.0, -1.0])\n",
        "    fourth_quad = first_quad - torch.tensor([0.0, 2.0])\n",
        "\n",
        "    noise = torch.cat((first_quad, second_quad, third_quad, fourth_quad), dim=0)\n",
        "    return noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94070200",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "94070200",
        "outputId": "525e767c-bfa0-41bf-f6e2-69924097884f"
      },
      "outputs": [],
      "source": [
        "data_dist = make_checker_board(200)\n",
        "init_dist = torch.randn_like(data_dist)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(init_dist[:, 0], init_dist[:, 1])\n",
        "plt.title(\"Initial Duistribution\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(data_dist[:, 0], data_dist[:, 1], c='violet')\n",
        "plt.title(\"Target Distribution\")\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e802e92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e802e92",
        "outputId": "97171e47-6163-472c-daa3-4216bd400052"
      },
      "outputs": [],
      "source": [
        "init_dist.shape, data_dist.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2740eed9",
      "metadata": {
        "id": "2740eed9"
      },
      "source": [
        "## Simple Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21085686",
      "metadata": {
        "id": "21085686"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2b422b3",
      "metadata": {
        "id": "c2b422b3"
      },
      "outputs": [],
      "source": [
        "class FlowMatchingModel(nn.Module):\n",
        "    def __init__(self, input_dim:int = 2):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_dim+1, 16), nn.ReLU(),\n",
        "            nn.Linear(16, 32), nn.ReLU(),\n",
        "            nn.Linear(32, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 512), nn.ReLU(),\n",
        "            nn.Linear(512, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 32), nn.ReLU(),\n",
        "            nn.Linear(32, 16), nn.ReLU(),\n",
        "            nn.Linear(16, 2)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x:torch.tensor, t:torch.tensor):\n",
        "        x = torch.cat((x, t), dim=-1)\n",
        "        return self.layer(x)\n",
        "\n",
        "    def step(self, x_t:torch.tensor, t:torch.tensor, dt:torch.tensor):\n",
        "        time_delta = dt/2\n",
        "        mid_u_t = self(x_t, t)\n",
        "        mid_x_t = x_t + mid_u_t * time_delta\n",
        "        u_t = self(mid_x_t, t+time_delta)\n",
        "        x_t = mid_x_t + u_t * time_delta\n",
        "        return x_t\n",
        "\n",
        "    @torch.no_grad\n",
        "    def sample(self, x_0:torch.tensor, num_step:int):\n",
        "        self.prob_paths = []\n",
        "        self.time = []\n",
        "        x_t = x_0\n",
        "        time_steps = torch.linspace(0.0, 1.0, num_step).to(device)\n",
        "        self.prob_paths.append(x_0.detach().cpu().numpy())\n",
        "        self.time.append(0.0)\n",
        "\n",
        "        for i in range(len(time_steps)-1):\n",
        "            dt = time_steps[i+1] - time_steps[i]\n",
        "            t = torch.full((x_t.shape[0], 1), time_steps[i]).to(device)\n",
        "            x_t = self.step(x_t, t, dt)\n",
        "            self.prob_paths.append(x_t.detach().cpu().numpy())\n",
        "            self.time.append(time_steps[i+1])\n",
        "        return x_t"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f4c40da",
      "metadata": {
        "id": "8f4c40da"
      },
      "source": [
        "## Training Flow Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa770daf",
      "metadata": {
        "id": "fa770daf"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = FlowMatchingModel().to(device=device)\n",
        "Loss = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ebbdac7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2ebbdac7",
        "outputId": "e8a9c777-2278-483c-836b-cbd208d51b62"
      },
      "outputs": [],
      "source": [
        "epochs = 3000\n",
        "for epoch in range(epochs):\n",
        "    target = make_checker_board(300).to(device)\n",
        "    noise = torch.randn_like(target)\n",
        "    t = torch.rand(target.shape[0], 1).to(device)\n",
        "\n",
        "    xt = ( 1- t) * noise + t * target\n",
        "    output = model(xt, t)\n",
        "\n",
        "    loss = Loss(output, target-noise)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "    print(f\"epoch : {epoch+1}/{epochs}: Loss : {loss.item()}\")\n",
        "\n",
        "# target = torch.tensor(make_moons(1000, noise=0.05, shuffle=True)[0], dtype=torch.float32).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377ce27a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "377ce27a",
        "outputId": "353efbe0-aa9e-41b1-a9de-672c8cd87c8d"
      },
      "outputs": [],
      "source": [
        "num_steps = 20\n",
        "x_0 = torch.randn(2000, 2).to(device)\n",
        "x_1 = model.sample(x_0, num_steps)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(x_0[:, 0].detach().cpu().numpy(), x_0[:, 1].detach().cpu().numpy())\n",
        "plt.grid(True)\n",
        "plt.title(\"Gaussian Distribution\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(x_1[:, 0].detach().cpu().numpy(), x_1[:, 1].detach().cpu().numpy())\n",
        "plt.grid(True)\n",
        "plt.title(\"Predicted Data Distribution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efc4fe35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "efc4fe35",
        "outputId": "df0355b6-51a5-4115-cac9-aa6b6263e18a"
      },
      "outputs": [],
      "source": [
        "Row, Col = 4, 4\n",
        "fig, axes = plt.subplots(Row, Col, figsize=(20, 20))\n",
        "indexes = torch.linspace(0, num_steps-1, Row*Col, dtype=torch.int32)\n",
        "\n",
        "for i in range(len(indexes)):\n",
        "    row = i // Row\n",
        "    col = i % Col\n",
        "    index = indexes[i]\n",
        "\n",
        "    axes[row, col].scatter(model.prob_paths[index][:, 0], model.prob_paths[index][:, 1])\n",
        "    axes[row, col].grid(True)\n",
        "    axes[row, col].set_title(f\"Time Step {model.time[index]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "313a91a9",
      "metadata": {},
      "source": [
        "## Flow Matching - MNIST DATA (Unguided)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dsD2ahOlrppk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsD2ahOlrppk",
        "outputId": "842452c9-bc0d-457f-e74a-419ef0c73c4c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65671f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "sys.path.append('/home/arafat/projects/deeplearning_crash_course/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "775ae7a7",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data/Images(500x500)-001.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-420429557.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/Images(500x500)-001.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/WriterInfo.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/Images(500x500)-001.npy'"
          ]
        }
      ],
      "source": [
        "data = np.load('../data/Images(500x500)-001.npy')\n",
        "label = np.load('../data/WriterInfo.npy')\n",
        "data.shape, label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d835e9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "Row, Col = 4, 4\n",
        "fig, axes = plt.subplots(Row, Col, figsize=(15, 8))\n",
        "\n",
        "for i in range(Row*Col):\n",
        "    index = np.random.randint(0, data.shape[0])\n",
        "    row_idx = i // Col\n",
        "    col_idx = i % Col\n",
        "\n",
        "    axes[row_idx, col_idx].imshow(data[index], cmap='gray')\n",
        "    axes[row_idx, col_idx].set_title(f\"Label : {label[index][0]}\")\n",
        "    axes[row_idx, col_idx].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2781966c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# index = np.random.randint(0, data.shape[0])\n",
        "# img = cv2.resize(data[index], (256, 256), cv2.INTER_LINEAR)\n",
        "\n",
        "# plt.subplot(1,2,1)\n",
        "# plt.imshow(data[index], cmap='gray')\n",
        "# plt.title(\"Real Image\")\n",
        "\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.imshow(img, cmap='gray')\n",
        "# plt.title(\"shrinked Image\")\n",
        "\n",
        "# image = torch.tensor(data[index]/255.0, dtype=torch.float32)\n",
        "# image.dtype\n",
        "# label[index][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eefc81e",
      "metadata": {},
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5152f59",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af54ba8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MNISTData(Dataset):\n",
        "    def __init__(self, file_path:str, label_path:str):\n",
        "        super().__init__()\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"File does not exists at : {file_path}\")\n",
        "        if not os.path.exists(label_path):\n",
        "            raise FileNotFoundError(f\"File does not exists at : {label_path}\")\n",
        "        \n",
        "        self.data = np.load(file_path)\n",
        "        self.label = np.load(label_path)\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = torch.tensor(cv2.resize(self.data[index], (256, 256), cv2.INTER_LINEAR), dtype=torch.float32).unsqueeze(dim=0)\n",
        "        # label = self.label[index][0]\n",
        "        noise = torch.randn_like(image)\n",
        "        t = torch.rand(1)\n",
        "        x_t = (1 - t) * noise + t * image\n",
        "        return image, noise, x_t, t\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd66c75",
      "metadata": {},
      "source": [
        "**Test Dataset & DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e32225b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# file_path = 'D:/notebook/deeplearning_crash_course/data/Images(500x500)-001.npy'\n",
        "# label_path = 'D:/notebook/deeplearning_crash_course/data/WriterInfo.npy'\n",
        "# train_dataset = MNISTData(file_path, label_path)\n",
        "# dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb70c87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# image, noise, x_t, t = next(iter(dataloader))\n",
        "# image.shape, noise.shape, x_t.shape, t.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c28f85f",
      "metadata": {},
      "source": [
        "## Flow Matching Model For MNIST **(Guided & Unguided)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "695e171f",
      "metadata": {},
      "source": [
        "![Model architecture](../model_architecture.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427552a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98a07bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "class EmbeddingLayer(nn.Module):\n",
        "    def __init__(self, in_dim:int=1, h_dim:int=16):\n",
        "        super().__init__()\n",
        "        assert h_dim % 2 == 0, \"h_dim must be divided by zero\"\n",
        "        self.in_dim = in_dim\n",
        "        self.half_dim = h_dim // 2\n",
        "\n",
        "        self.w = nn.Parameter(torch.rand(1, self.half_dim))\n",
        "    \n",
        "    def forward(self, t:torch.tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            t: dim(bs, 1) -> dim(bs, time)\n",
        "        Returns:\n",
        "            t_embed: dim(bs, h_dim)\n",
        "        \"\"\"\n",
        "        freqs = t @ self.w\n",
        "        sin_embeds = torch.sin(2 * torch.pi * freqs)\n",
        "        cos_embeds = torch.cos(2 * torch.pi * freqs)\n",
        "        embeddings = torch.zeros(t.shape[0], self.half_dim*2, device=t.device)\n",
        "        embeddings[:, 0::2] = sin_embeds\n",
        "        embeddings[:, 1::2] = cos_embeds\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec22c50",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualLayer(nn.Module):\n",
        "    def __init__(self, channel:int, mlp_dim:int):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(channel),\n",
        "            nn.SiLU()\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(channel),\n",
        "            nn.SiLU()\n",
        "        )\n",
        "        self.MLP = nn.Sequential(\n",
        "            nn.Linear(mlp_dim, channel),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x:torch.tensor, t:torch.tensor):\n",
        "        residual = x.clone()\n",
        "        t = self.MLP(t).unsqueeze(-1).unsqueeze(-1)\n",
        "        x = self.layer1(x) + t\n",
        "        x = self.layer2(x) + residual\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df42d588",
      "metadata": {},
      "outputs": [],
      "source": [
        "class DownSampleLayer(nn.Module):\n",
        "    def __init__(self, in_channel:int, out_channel:int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x:torch.tensor):\n",
        "        return self.layer(x)\n",
        "    \n",
        "class UpSampleLayer(nn.Module):\n",
        "    def __init__(self, in_channel:int, out_channel:int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channel, out_channel, kernel_size=2, stride=2, padding=0),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x:torch.tensor):\n",
        "        return self.layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59249be2",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channel:int, out_channel:int, mlp_dim:int):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.res_layers = nn.ModuleList([\n",
        "            ResidualLayer(in_channel, mlp_dim) for _ in range(2)\n",
        "        ])\n",
        "\n",
        "        self.down_sample = DownSampleLayer(in_channel, out_channel)\n",
        "\n",
        "    def forward(self, x:torch.tensor, t:torch.tensor):\n",
        "        for layer in self.res_layers:\n",
        "            x = layer(x, t)\n",
        "        return self.down_sample(x)\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channel:int, out_channel:int, mlp_dim:int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.res_layers = nn.ModuleList([\n",
        "            ResidualLayer(out_channel, mlp_dim) for _ in range(2)\n",
        "        ])\n",
        "\n",
        "        self.up_sample = UpSampleLayer(in_channel, out_channel)\n",
        "\n",
        "    def forward(self, x:torch.tensor, t:torch.tensor):\n",
        "        x = self.up_sample(x)\n",
        "        for layer in self.res_layers:\n",
        "            x = layer(x, t)\n",
        "        return x\n",
        "    \n",
        "\n",
        "class Midcoder(nn.Module):\n",
        "    def __init__(self, channels:int, mlp_dim:int):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            ResidualLayer(channels, mlp_dim) for _ in range(3)\n",
        "        ])\n",
        "\n",
        "\n",
        "    def forward(self, x:torch.tensor, t:torch.tensor):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, t)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98803979",
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnGuidedFlowMatching(nn.Module):\n",
        "    def __init__(self, in_channel:int, embed_dim:int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.channels = [32, 64, 128, 256, 512]\n",
        "        self.init_conv = nn.Conv2d(in_channel, self.channels[0], kernel_size=3, padding=1)\n",
        "        self.final_conv = nn.Conv2d(self.channels[0], in_channel, kernel_size=3, padding=1)\n",
        "\n",
        "        self.embedding = EmbeddingLayer(h_dim=embed_dim)\n",
        "        self.encoders = nn.ModuleList([\n",
        "            Encoder(ch1, ch2, embed_dim) for ch1, ch2 in zip(self.channels[:-1], self.channels[1:])\n",
        "        ])\n",
        "        self.decoders = nn.ModuleList([\n",
        "            Decoder(ch1, ch2, embed_dim) for ch1, ch2 in zip(self.channels[::-1][:-1], self.channels[::-1][1:])\n",
        "        ])\n",
        "        self.bottle_neck = Midcoder(self.channels[-1], embed_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x:torch.tensor, t:torch.tensor):\n",
        "        intermediate_xt = []\n",
        "\n",
        "        time_embed = self.embedding(t)\n",
        "        x_t = self.init_conv(x)\n",
        "\n",
        "        for encoder in self.encoders:\n",
        "            x_t = encoder(x_t, time_embed)\n",
        "            intermediate_xt.append(x_t.clone())\n",
        "        \n",
        "        x_t = self.bottle_neck(x_t, time_embed)\n",
        "\n",
        "        for decoder in self.decoders:\n",
        "            x_t += intermediate_xt.pop()\n",
        "            x_t = decoder(x_t, time_embed)\n",
        "        \n",
        "        u_t = self.final_conv(x_t)\n",
        "        return u_t\n",
        "        \n",
        "    \n",
        "    def step(self, x_t:torch.tensor, t:torch.tensor, dt:torch.tensor):\n",
        "        time_delta = dt/2\n",
        "        mid_u_t = self(x_t, t)\n",
        "        mid_x_t = x_t + mid_u_t * time_delta\n",
        "        u_t = self(mid_x_t, t+time_delta)\n",
        "        x_t = mid_x_t + u_t * time_delta\n",
        "        return x_t\n",
        "\n",
        "    @torch.no_grad\n",
        "    def sample(self, x_0:torch.tensor, num_step:int):\n",
        "        self.prob_paths = []\n",
        "        self.time = []\n",
        "        x_t = x_0\n",
        "        time_steps = torch.linspace(0.0, 1.0, num_step).to(device)\n",
        "        self.prob_paths.append(x_0.squeeze(0).permute(1,2,0).detach().cpu().numpy())\n",
        "        self.time.append(0.0)\n",
        "\n",
        "        for i in range(len(time_steps)-1):\n",
        "            dt = time_steps[i+1] - time_steps[i]\n",
        "            t = torch.full((x_t.shape[0], 1), time_steps[i]).to(device)\n",
        "            x_t = self.step(x_t, t, dt)\n",
        "            \n",
        "            vis_tensor = x_t.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
        "            self.prob_paths.append(vis_tensor)\n",
        "            self.time.append(time_steps[i+1])\n",
        "        return x_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d779d6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# model = UnGuidedFlowMatching(1, 16)\n",
        "\n",
        "# B, C, H, W = 10, 1, 256, 256\n",
        "# dummy_img = torch.rand(B, C, H, W)\n",
        "# dummy_time = torch.rand(B, 1)\n",
        "# dummy_img.shape, dummy_time.shape\n",
        "\n",
        "# model.eval()\n",
        "# out = model(dummy_img, dummy_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa565572",
      "metadata": {},
      "source": [
        "### **Training Unguided**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e103e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn import MSELoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d3ec920",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = UnGuidedFlowMatching(1, 16).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3bbe17",
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = '../data/Images(500x500)-001.npy'\n",
        "label_path = '../data/WriterInfo.npy'\n",
        "train_dataset = MNISTData(file_path, label_path)\n",
        "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b184e84",
      "metadata": {},
      "outputs": [],
      "source": [
        "critetion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1810dcc",
      "metadata": {},
      "source": [
        "### **Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7fa89c",
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "iteration = 0\n",
        "for epoch in range(epochs):\n",
        "    loss = 0.0\n",
        "    for image, noise, x_t, t in dataloader:\n",
        "        \n",
        "        image = image.to(device)\n",
        "        noise = noise.to(device)\n",
        "        x_t = x_t.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        out = model(x_t, t)\n",
        "        Loss = critetion(out, image - noise)\n",
        "        loss += Loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        Loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    iteration += 1\n",
        "    if iteration % 5 == 0:\n",
        "        file_name = f\"unguided_model_weight_{epoch}.pth\"\n",
        "        torch.save(model.state_dict(), file_name)\n",
        "\n",
        "    print(f\"epoch : {epoch+1}/{epochs} | Loss : {loss/len(dataloader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07098539",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_steps = 20\n",
        "x_0 = torch.randn(1, 1, 256, 256).to(device)\n",
        "x_1 = model.sample(x_0, num_steps)\n",
        "\n",
        "Row, Col = 3, 3\n",
        "fig, axes = plt.subplots(Row, Col, figsize=(20, 20))\n",
        "indexes = torch.linspace(0, num_steps-1, Row*Col, dtype=torch.int32)\n",
        "\n",
        "for i in range(len(indexes)):\n",
        "    row = i // Col  # Fixed: divide by number of columns\n",
        "    col = i % Col\n",
        "    index = indexes[i].item()  # Fixed: convert tensor to Python int\n",
        "    axes[row, col].imshow(model.prob_paths[index], cmap='gray')\n",
        "    axes[row, col].grid(True)\n",
        "    axes[row, col].set_title(f\"Time Step {model.time[index]:.3f}\")  # Fixed: format float\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b95f19ba",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d557c707",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
